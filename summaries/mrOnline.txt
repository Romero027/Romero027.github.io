MapReduce is a shared-nothing architecture, which is tuned for massive data parallelism. Mappers operate on portions of the input, and reducers are responsible for specific groups. In this design, the output of both map and reduce tasks are written to disk before it can be consumed.[1] However,  MapReduce is often used for analytics on streams of data that arrive continuously. Such design will result in extremely slow job completion time. 
This paper presents the Hadoop Online Prototype(HOP), which is a pipelined version of MapReduce. It allows maps to operate on infinite data and reduces to export early answers. To support pipelining, HOP modified the upstream task to push data to the downstream task instead, as it is produced. To fully utilize the benefit of the combiner[2], HOP will wait for the buffer to grow to a threshold size, instead of sending the buffer contents to reducers directly. To simplify the fault tolerance of HOP, the reducer treats the output of a pipelined map task as tentative until the master informs the reducer. Thus, the reducer could just ignore any tentative spill[3] files produced by the failed map attempt. 
To support interactive data analysis, HOP also provides online aggregation functionality. It simply applies the reduce function to the data that a reduce task has received so far, and report the output as well as the job progress to the user.

Comments:
The idea of proactively push data is great as it saves lots of I/Os imposed by the traditional MapReduce framework. However, it seems like task rescheduling and straggler handling are becoming more difficult. Also, multi-job online aggregation is really hard to implement, because the relation of outputs may vary. 


[1]Note that this means a reduce task cannot fetch the output of a map task until the map has finished executing and committed its final output to disk. 
[2]the role of combiners are to pre-aggregate map output locally, similar to the reduce step in wordcount. 
[3] spill files = small sorted runs