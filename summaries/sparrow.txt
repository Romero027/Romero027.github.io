The motivation behind this paper is the trend that modern data analytic systems are running ever shorter and higher-fanout jobs[1]. As a result, scheduling decisions must be made at very high throughput.[2] Thus, the existing centralized scheduler cannot meet our requirements.
First, we need to understand what are the design goals. To support a workload composed of sub-second[3] tasks, a scheduler must provide millisecond-scale scheduling delay and support millions of task scheduling decisions per second. We also want to ensure scheduling quality. (e.g., we might wish to distribute the tasks uniformly) Moreover, the scheduler needs to tolerate failure(it needs to recover from failures quickly.) The existing centralized scheduler can provide quality placement since they maintain a complete view of which tasks are running on which worker machines, but they do not meet other requirements. 
Sparrow adopts the decentralized approach, in which many schedulers run in parallel, and they are stateless.[4][7] Sparrow uses a technique called batch sampling, instead of naive per-task sampling. It can improve the strawman solution because it allows all probes for a particular job to share information. To schedule using batch sampling, a scheduler randomly selects dm worker machines. (where d>=1 and m is the number of tasks within a job), and schedule the m tasks to the m least loaded workers. We might argue that queue length is a poor indicator of the wait time.[6]Also, Sampling suffers from race conditions since we have many schedulers. They might concurrently place tasks on the lightly loaded worker. To address these problems, Sparrow uses a technique called late binding. Instead of replying to the probes immediately after receiving it, the worker will treat the probes as tasks and place them into the queue. Thus, the previous method becomes "the scheduler assigns the job's tasks to the first m workers to reply." 

Comment: This paper is extremely well written as they explain their approaches(which, I would argue,  are quite straightforward) very clear. I really like the late bind idea as it solves two problems at once. However, the authors make some strong assumptions. They assume the latency is zero, which is right within a data center, but the latency across data centers may be O(100ms), making Sparrow not a good fit for geo-distributed data analytics. They also assume jobs are single wave, but in real-world jobs might run as multiple waves of tasks.[8]


[1] higher degree of parallelism
[2]For example, in the paper, the authors claim that a cluster containing ten thousand 16-core machines and running 100ms tasks may require 1 million scheduling decisions per second. 
[3]The authors predict that the tasks are going to be shorter and shorter.
[4]Some terminology: A cluster composed of worker machines, each has a fixed number of slots, and schedules. A job consists of many tasks. If the worker is currently fully utilized, it will queue new tasks until resources become available again. 
[5]A naive approach is to do per-task sampling by using the power of two choices. The scheduler places each task on the least loaded of two randomly selected worker machines. Note that the scheduler must first send a probe to the two randomly selected workers. 
[6]Consider a scenario in which node A has one 500ms task, but node b has five 10ms tasks
[7]They might share the information across tasks when possible.
[8] Multi-wave means the number of tasks in a job or stage is greater than the number of available slots.