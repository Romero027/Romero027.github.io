  This is one of the classic paper in the field of distributed system. The authors describe the design and the performance of Google File system, which is targeted for large distributed data-intensive applications. Key assumptions of GFS include 1. (partial) failures are common(because it is built from inexpensive components) 2.it needs to support both small and large files. 3. workloads are append-only(i.e. no overwrites) 4. the system must be optimized for concurrent access by multiple clients.
  
  A GFS cluster consists of a single master(which is the name node in Hadoop) and multiple chunck servers(which is the data nodes in Hadoop). The master maintains all file system metadata[1] in memory and uses heartbeat messages to keep an updated global view of the cluster.  GFS will divide files into fixed-size chunks[2] and store three replicas[3][5] for each 
chunk

Strong points:
  1. I was surprised by the simplicity of the design. There's no complex algorithms/protocols involved.
  2. Although GFS has a centralized master(which could be the bottleneck and single point of failure, they used many clever ideas[4] to 1.reduce the size of metadata the master need to store 2. reduce the interaction between client and the master 3. achieve fault tolerance

Weakness:
  1.GFS has a relaxed consistency model to support its highly distributed operations, which means clients may see stale data.
  2. It is not optimized for small files and does not support operations other than append-only.
  3. Although it uses some techniques to reduce the workload of master, if the data size grows to fast, the master will eventually run out of memory or becomes the bottleneck. ( I guess this problem could be partially solved by having a master for each rack?)

NOTE:
[1] There are three major types of metadata: 1. The file namespaces. 2. The chunk namespaces 3. the mapping from files to chunks.  (first two types are also stored in the disk for fault tolerance)
[2] chunk size is configurable but 64MB by default(Note large chunk size has several advantages. However, it also makes GFS bad for small files.)
[3] also configurable. Note that it may store the replicas across racks in case of rack failures.
[4]It uses techniques such as not storing the chunk location persistently, make the client cache chunk locations and master replication. 
[5]GFS uses primary-backup-like approach for replication. " we replicate it on multiple remote machines and respond to a client operation only after flushing the corresponding log record to disk
both locally and remotely"
